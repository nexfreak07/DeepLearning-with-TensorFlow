{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwriting Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4Gt2yHtfsYN7raPBLlhbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nexfreak07/DeepLearning-with-TensorFlow/blob/main/Handwriting_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "rk64CfMdTIKS",
        "outputId": "d9ba4270-d077-446f-e7a4-963a0583cba1"
      },
      "source": [
        "import csv\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from os import getcwd\r\n",
        "\r\n",
        "\r\n",
        "def get_data(filename):\r\n",
        "    with open(filename) as training_file:\r\n",
        "        images = []\r\n",
        "        labels = []\r\n",
        "        training_file.readline()\r\n",
        "        for row in training_file:\r\n",
        "            row = row.split(',')\r\n",
        "            label = np.array(row[0]).astype(np.float)\r\n",
        "            image_string = np.array(row[1:785]).astype(np.float)\r\n",
        "            \r\n",
        "            image = np.array_split(image_string, 28)\r\n",
        "            \r\n",
        "            label = np.array(label) \r\n",
        "            image = np.array(image) \r\n",
        "            \r\n",
        "            labels = np.append(labels, label)\r\n",
        "            images.append(image)\r\n",
        "            \r\n",
        "    labels = np.array(labels).astype(float)\r\n",
        "    images = np.array(images).astype(float)\r\n",
        "    return images, labels\r\n",
        "\r\n",
        "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\r\n",
        "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\r\n",
        "training_images, training_labels = get_data(path_sign_mnist_train)\r\n",
        "testing_images, testing_labels = get_data(path_sign_mnist_test)\r\n",
        "\r\n",
        "training_images = np.expand_dims(training_images, axis = -1) \r\n",
        "testing_images = np.expand_dims(testing_images, axis = -1) \r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    # Your Code Here\r\n",
        "    rescale = 1./255,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    shear_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest'\r\n",
        "    )\r\n",
        "\r\n",
        "validation_datagen = ImageDataGenerator(\r\n",
        "    rescale = 1./255.\r\n",
        "    )\r\n",
        "    \r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\r\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\r\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'),\r\n",
        "    tf.keras.layers.Dense(25, activation = 'softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer = 'rmsprop', loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\r\n",
        "\r\n",
        "history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size = 10),\r\n",
        "                              validation_data = validation_datagen.flow(testing_images, testing_labels, batch_size = 10),\r\n",
        "                              epochs = 25)\r\n",
        "\r\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-572d93e64a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mpath_sign_mnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpath_sign_mnist_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-572d93e64a10>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/../tmp2/sign_mnist_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e6btG4ATQH1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}